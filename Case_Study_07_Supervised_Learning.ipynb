{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Case Study #07- Supervised Learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case study on Supervised learning\n",
        "\n",
        "Do the following in the iris dataset.\n",
        "1. Read the dataset to the python environment.\n",
        "2. Do necessary pre-processing steps.\n",
        "3. Find out which classification model gives the best result to predict iris\n",
        "species.(also do random forest algorithm)"
      ],
      "metadata": {
        "id": "OCGyzPxzQN1A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uau9vqdkOwwX"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Read the dataset to the python environment."
      ],
      "metadata": {
        "id": "D8ub0YiXQM9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the excel file into a pandas dataframe.\n",
        "iris_data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Week 11/Activity/Case Study/iris.xls')"
      ],
      "metadata": {
        "id": "OJszVlvpQkcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data\n",
        "iris_data.head()"
      ],
      "metadata": {
        "id": "MJ7PxrWZQkmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of elements in each dimension (Rows and Columns)\n",
        "iris_data.shape"
      ],
      "metadata": {
        "id": "A4ZmkN55QksK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data\n",
        "iris_data.info()"
      ],
      "metadata": {
        "id": "6-ik8F0rQkxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the columns in the dataset\n",
        "iris_data.columns"
      ],
      "metadata": {
        "id": "3oC1yGIDaClt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the iris dataset :\n",
        "\n",
        "- 50 samples of 3 different species of iris (150 samples total)\n",
        "- Measurements: sepal length, sepal width, petal length, petal width\n"
      ],
      "metadata": {
        "id": "P7yeaWwPSTiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the target variable\n",
        "iris_data['Classification'].value_counts()"
      ],
      "metadata": {
        "id": "6ONL47tyQk7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that the feature 'Classification' is the target variable in the iris dataset (whether the iris classifcation there are 50 observations of each species (setosa, versicolor, virginica). Hence it is a Multi-Class Classification Problem"
      ],
      "metadata": {
        "id": "rkUg0lz4VmLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Do necessary pre-processing steps."
      ],
      "metadata": {
        "id": "Kdh82sT5YUIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data type for all features in the dataset\n",
        "iris_data.dtypes"
      ],
      "metadata": {
        "id": "PPVgPlGAl92P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to check whether any null or missing values present in the iris dataset"
      ],
      "metadata": {
        "id": "_artqhC1VwLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the null values present in each columns in the dataset (Before treatment)\n",
        "iris_data.isna().sum()"
      ],
      "metadata": {
        "id": "yDrts4y0V4sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that there are 19 null or missing values present in the iris dataset. The features sepal length(SL), sepal width(SW) and petal length(PL) are having the null values. we can treat the null values. Since sepal length(SL), sepal width(SW) and petal length(PL) are float data type so we can fill the missing values with mean/median method."
      ],
      "metadata": {
        "id": "BxZYnawCWMSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data before missing values treatment\n",
        "iris_data[iris_data.isna().any(axis=1)] # check at least one null values in a row "
      ],
      "metadata": {
        "id": "Lw3M3P0hV4dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use plots and summary statistics to help identify missing or corrupt data."
      ],
      "metadata": {
        "id": "pTD6QN9Qa-Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can plot the frequency graph\n",
        "freq_graph = iris_data.select_dtypes(include=['float64'])\n",
        "freq_graph.hist(figsize=(15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TOsZVBG3cSlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above frequency graph we can say that sepal length(SL), sepal width(SW) , petal length(PL) and Petal Width(PW) are follows almost normal distribution so we can use mean for missing values treatment."
      ],
      "metadata": {
        "id": "ZuzGoCRjdBwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Statistical summary of iris dataset\n",
        "iris_data.describe().T"
      ],
      "metadata": {
        "id": "pH8zfcCSbE9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \"Missing values are frequently indicated by out-of-range entries; perhaps a negative number (e.g., -1) in a numeric field that is normally only positive, or a 0 in a numeric field that can never normally be 0\"."
      ],
      "metadata": {
        "id": "WEeYx5EUbd14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the complete statistical summary of count, mean, statndard deviation, minimum value of each column also maximum, 25%, 50% and 75% percentile."
      ],
      "metadata": {
        "id": "VM11TjNobyIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can use a loop to treat missing or null values for sepal length(SL), sepal width(SW) and petal length(PL)"
      ],
      "metadata": {
        "id": "gnds7xolf1ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill the missing values\n",
        "missing_val = ['SL','SW','PL']\n",
        "\n",
        "for i in missing_val:\n",
        "    iris_data[i] = iris_data[i].fillna(iris_data[i].mean())"
      ],
      "metadata": {
        "id": "TagJtbBva9Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the null values present in each columns in the dataset (After treatment)\n",
        "iris_data.isna().sum()"
      ],
      "metadata": {
        "id": "sd6wRWLxgmsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data after missing values treatment\n",
        "iris_data[iris_data.isna().any(axis=1)] # check at least one null values in a row "
      ],
      "metadata": {
        "id": "-kRuLIiOgm47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that it is treated well for missing values in sepal length(SL), sepal width(SW) and petal length(PL). Now our iris dataset is completely treated with no null or missing values"
      ],
      "metadata": {
        "id": "YhdikDfTmNl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of elements in each dimension (Rows and Columns)\n",
        "iris_data.shape"
      ],
      "metadata": {
        "id": "_v_kJllggnDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So next we can check and handle outliers in the iris dataset. For finding outliers we can use boxplot."
      ],
      "metadata": {
        "id": "FHTnXOt6nBxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the columns in the dataset\n",
        "iris_data.columns"
      ],
      "metadata": {
        "id": "ZQaOWWqJnc7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot before removing the outliers from SL, SW, PL and PW features\n",
        "for i in iris_data.columns[iris_data.dtypes == float]:\n",
        "   fig = plt.figure(figsize=(8,5))\n",
        "   iris_data[i].value_counts(normalize=True).plot(kind='box')\n",
        "   fig.suptitle(i)"
      ],
      "metadata": {
        "id": "yRq1KZgBqmtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that there are some outliers present in the Sepal Width(SW) features so we need to remove the outliers."
      ],
      "metadata": {
        "id": "1rt1a1aOsOlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Sepal Width (SW) feature"
      ],
      "metadata": {
        "id": "YN353ey4Bz7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot before removing the outliers from Sepal Width feature\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "iris_data['SW'].value_counts(normalize=True).plot(kind='box')\n",
        "fig.suptitle('Sepal Width')"
      ],
      "metadata": {
        "id": "uAtekHALWFav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For removing outliers first we need to check the quartiles. It manages the outliers.\n",
        "Q1 = np.percentile(iris_data['SW'],25,interpolation='midpoint')\n",
        "Q2 = np.percentile(iris_data['SW'],50,interpolation='midpoint')\n",
        "Q3 = np.percentile(iris_data['SW'],75,interpolation='midpoint')\n",
        "print('Q1: ',Q1,'\\nQ2: ',Q2,'\\nQ3: ',Q3)\n",
        "\n",
        "# check the inter quartile range (IQR)\n",
        "IQR = Q3 - Q1\n",
        "print('IQR: ',round(IQR,2))\n",
        "\n",
        "#check the lower and upper limit \n",
        "low_lm = Q1-1.5*IQR\n",
        "upp_lm = Q3+1.5*IQR\n",
        "print(\"Lower limit is : \",round(low_lm,2))\n",
        "print(\"Upper limit is : \",round(upp_lm,2))\n",
        "\n",
        "'''Normally the datapoints which fall below Q1-1.5(IQR) and above Q3+1.5(IQR) are considered as outliers.\n",
        " If the value above the upper limit or below the lower limit we need to remove that outliers.'''\n",
        "\n",
        " # display the outilers\n",
        "outliers = []\n",
        "for i in iris_data['SW']:\n",
        "  if((i>upp_lm)or(i<low_lm)):\n",
        "    outliers.append(i)\n",
        "\n",
        "print(\"Outliers in the Sepal Width: \",outliers)"
      ],
      "metadata": {
        "id": "sZtCb-PLB6fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that these values are the outliers in the Sepal Width feature and also we can observe that there is one lower limit value and remaining all the upper limit values as outliers. Now we need to find the index values for the outliers. "
      ],
      "metadata": {
        "id": "m37TSV6nCRjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select the index of these outliers\n",
        "indx_low = iris_data['SW']<low_lm\n",
        "outlier_indx_low = iris_data.loc[indx_low].index\n",
        "\n",
        "indx_upp = iris_data['SW']>upp_lm\n",
        "outlier_indx_upp= iris_data.loc[indx_upp].index\n",
        "\n",
        "print('The outliers index value of lower limit is {}'.format(outlier_indx_low),\n",
        "      '\\nand upper limit is {}'.format(outlier_indx_upp))"
      ],
      "metadata": {
        "id": "46jSmO4dC09s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop these index for removing outliers\n",
        "iris_data.drop(outlier_indx_low, inplace=True)\n",
        "iris_data.drop(outlier_indx_upp, inplace=True)"
      ],
      "metadata": {
        "id": "NV3B8cwxSC_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot after removing the outliers from Sepal Width feature\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "iris_data['SW'].value_counts(normalize=True).plot(kind='box')\n",
        "fig.suptitle('Sepal Width')"
      ],
      "metadata": {
        "id": "yhG1LDclUNzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above boxplot we can see that we reduced the outliers from the Sepal Width(SW) feature."
      ],
      "metadata": {
        "id": "k6ROXmFj0-n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data\n",
        "iris_data.info()"
      ],
      "metadata": {
        "id": "8P3raBBY0x2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Summary of the data\n",
        "iris_data.describe()"
      ],
      "metadata": {
        "id": "WTLq8buG0yjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For filling with mean did not introduce observable change in iris dataset"
      ],
      "metadata": {
        "id": "yxnvqwxAT3rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encode with target 'Classification' feature\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "iris_data['Classification'] = LabelEncoder().fit_transform(iris_data['Classification'])"
      ],
      "metadata": {
        "id": "A5SqgPQaUJZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the target variable after label encode\n",
        "iris_data['Classification'].value_counts()"
      ],
      "metadata": {
        "id": "tm07DYV1U-65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Find out which classification model gives the best result to predict iris species.(also do random forest algorithm)"
      ],
      "metadata": {
        "id": "YXZ5WGLvuHFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check model performances\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "def check_model_metrices(y_test, y_pred):\n",
        "    print('Model Accuracy = ', accuracy_score(y_test, y_pred))\n",
        "    print('Model Precision = ', precision_score(y_test, y_pred, average='micro'))\n",
        "    print('Model Recall = ', recall_score(y_test, y_pred, average='micro'))\n",
        "    print('Model F1 Score = ', f1_score(y_test, y_pred, average='micro'))\n",
        "    print('Confusion Matrix = \\n', confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "v0q-W8GbWxVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature columns\n",
        "feature_cols = list(iris_data.columns[:-1])\n",
        "\n",
        "# Extract target column 'CLassification'\n",
        "target_col = iris_data.columns[-1] \n",
        "\n",
        "# Separate the data into feature data and target data (X and y, respectively),this method is called feature selection\n",
        "X = iris_data[feature_cols]\n",
        "y = iris_data[target_col]\n",
        "print(f'Feature shape: {X.shape}')"
      ],
      "metadata": {
        "id": "kj4gsAQfVb88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data into train and test \n",
        "from sklearn.model_selection import train_test_split\n",
        "# training points (approximately 70%) and testing points (approximately 30%).\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
        "\n",
        "# Show the results of the split\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
      ],
      "metadata": {
        "id": "BJQEbjU4XOuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1. Multinomial Logistic regression"
      ],
      "metadata": {
        "id": "-e4HKv9TPuZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(multi_class='multinomial', solver='newton-cg') # solver - Algorithm to use in the optimization\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)\n"
      ],
      "metadata": {
        "id": "sZ6ytz9ZVNVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, lr_pred)"
      ],
      "metadata": {
        "id": "NSbwp8dMlgYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For good model, accuracy and F1 score should be maximum possible. As per the Multinomial Logistic regression model has performed well with an accuracy of 88.63% with just 5 misclassification."
      ],
      "metadata": {
        "id": "0_kWRIXyYW4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: K-Nearest Neighbors(KNN)"
      ],
      "metadata": {
        "id": "Uhbi9D5KQJBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "acc_values = [] #find the optimum k values\n",
        "neighbors = np.arange(3,16)\n",
        "for k in neighbors:\n",
        "  classifier = KNeighborsClassifier(n_neighbors=k, metric='minkowski')\n",
        "  classifier.fit(X_train,y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  acc = accuracy_score(y_test,y_pred) # find the maximum accuracy\n",
        "  acc_values.append(acc)\n",
        "\n",
        "acc_values"
      ],
      "metadata": {
        "id": "H3XpJpMWP5Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(neighbors, acc_values,'o-')\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('accuracy')"
      ],
      "metadata": {
        "id": "4WOXpiwOQTXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see best k value is 3"
      ],
      "metadata": {
        "id": "hdy43BFDQWB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can make the model with k value as 3\n",
        "classifier = KNeighborsClassifier(n_neighbors=3, metric='minkowski')\n",
        "classifier.fit(X_train,y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LVV3ZSpAQULE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the  K-Nearest Neighbors(KNN) model has performed well with an accuracy of 93.18% with 3 misclassification."
      ],
      "metadata": {
        "id": "VXNvwFPZdRRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy and F1 Score is much improvement in KNN model"
      ],
      "metadata": {
        "id": "gU_Z-wjfQdxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: SVM(Support Vector Machine) with multi-class\n"
      ],
      "metadata": {
        "id": "vKh0N2NwdqUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Kernel have 3 types\n",
        "1. Linear\n",
        "2. Polynomial\n",
        "3. Radial Basis Function (RBF)"
      ],
      "metadata": {
        "id": "C8_NCA2fej6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "# decision_function_shape is set to One-vs_One for multi-class\n",
        "linear = SVC(kernel='linear', decision_function_shape='ovo') \n",
        "linear.fit(X_train, y_train)\n",
        "linear_pred = linear.predict(X_test)"
      ],
      "metadata": {
        "id": "zBA0PnLSdpyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, linear_pred)"
      ],
      "metadata": {
        "id": "wF0UWWC3QhwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the SVM(Support Vector Machine) with multi-class using linear kernel model has performed well with an accuracy of 90.90% with 4 misclassification.\n",
        "\n",
        "Accuracy and F1 Score is much improvement with Logistic Regression and not improved with KNN."
      ],
      "metadata": {
        "id": "cmv1-Q-ceNO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_function_shape is set to One-vs_One for multi-class\n",
        "poly = SVC(kernel='poly', degree = 3, decision_function_shape='ovo')\n",
        "poly.fit(X_train, y_train)\n",
        "poly_pred = poly.predict(X_test)"
      ],
      "metadata": {
        "id": "BRZECoFEfjIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, poly_pred)"
      ],
      "metadata": {
        "id": "6b37uUzefyEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the SVM(Support Vector Machine) with multi-class using polinomial kernel model has performed well with an accuracy of 93.18% with 3 misclassification.\n",
        "\n",
        "Accuracy and F1 Score is much improvement with Logistic Regression and SVM linear kernel not improved with KNN."
      ],
      "metadata": {
        "id": "GpDF9r05g8QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_function_shape is set to One-vs_One for multi-class\n",
        "rbf = SVC(kernel='rbf', decision_function_shape='ovo') \n",
        "rbf.fit(X_train, y_train)\n",
        "rbf_pred = rbf.predict(X_test)"
      ],
      "metadata": {
        "id": "rAdCPTKPfbd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, rbf_pred)"
      ],
      "metadata": {
        "id": "IFPAB8DqfcQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the SVM(Support Vector Machine) with multi-class using RBF kernel model has performed well with an accuracy of 86.63% with 6 misclassification.\n",
        "\n",
        "Accuracy and F1 Score is not improvement with other classification model."
      ],
      "metadata": {
        "id": "rEZOFdXJhXy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Decision Trees"
      ],
      "metadata": {
        "id": "C3eU0VOchtgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)"
      ],
      "metadata": {
        "id": "hAHoSFkTfcVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, dt_pred)"
      ],
      "metadata": {
        "id": "PdSkhCgAh80K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Random Forest"
      ],
      "metadata": {
        "id": "ZI_VZU3BhxZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "7am5Dq4ZfcaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function to check model performances\n",
        "check_model_metrices(y_test, rf_pred)"
      ],
      "metadata": {
        "id": "isfo-Y7rfcen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}